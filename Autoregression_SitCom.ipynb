{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyM9oe84OYnYBBaY2CZL2CZ2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahabday/NLP_learning/blob/main/Autoregression_SitCom.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "udPX-imve4cH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import preprocessing\n",
        "from tensorflow.keras import models, layers\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "import kagglehub\n",
        "import shutil\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading data from Kaggle\n"
      ],
      "metadata": {
        "id": "pXFDzTDhfnAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import kagglehub\n",
        "import shutil\n",
        "\n",
        "# Define the folder where the dataset will be stored\n",
        "output_folder = \"/content/scripts\"\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Download the dataset\n",
        "path = kagglehub.dataset_download(\"divyansh22/friends-tv-show-script\")\n",
        "\n",
        "print(\"✅ Dataset downloaded and saved in:\", path)\n",
        "\n",
        "# Copy all files from the source path to the destination\n",
        "shutil.copytree(path, output_folder, dirs_exist_ok=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "T6zAmJmcfZDe",
        "outputId": "9601abd5-8b07-44a1-c9c2-ddcb0e1e6e19"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.7), please consider upgrading to the latest version (0.3.8).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/divyansh22/friends-tv-show-script?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.67M/1.67M [00:01<00:00, 1.52MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "✅ Dataset downloaded and saved in: /root/.cache/kagglehub/datasets/divyansh22/friends-tv-show-script/versions/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/scripts'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The big bang theory data import .\n"
      ],
      "metadata": {
        "id": "7qTjT2l9f6uK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"mitramir5/the-big-bang-theory-series-transcript\")\n",
        "\n",
        "shutil.copytree(path, output_folder, dirs_exist_ok=True)\n",
        "\n",
        "# convert the csv to txt and save it\n",
        "df_script=pd.read_csv('/content/scripts/1_10_seasons_tbbt.csv')\n",
        "\n",
        "df = df_script\n",
        "\n",
        "# each row  :\n",
        "# if episonde name is the first time : create episod name\n",
        "# person scene : dialogue /n\n",
        "\n",
        "output_file = \"tbbt_script.txt\"\n",
        "seen_episodes = set()\n",
        "\n",
        "with open(output_folder + '/' + output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    for _, row in df.iterrows():\n",
        "        if row[\"episode_name\"] not in seen_episodes:\n",
        "            f.write(f\"\\n{row['episode_name']}\\n\")  # Write episode name\n",
        "            f.write(\"=\" * len(row[\"episode_name\"]) + \"\\n\")  # Underline episode name\n",
        "            seen_episodes.add(row[\"episode_name\"])\n",
        "\n",
        "        f.write(f\"{row['person_scene']}: {row['dialogue']}\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puPUdfFhfb0g",
        "outputId": "477310e8-de5e-4807-b6a7-d322b1c46441"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.7), please consider upgrading to the latest version (0.3.8).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/mitramir5/the-big-bang-theory-series-transcript?dataset_version_number=4...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.92M/1.92M [00:01<00:00, 1.78MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZX1ZFis_kFaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How I met Your Mother"
      ],
      "metadata": {
        "id": "RYeUkUp8tYJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"gibsonhu85/howimetyourmotherscript\")\n",
        "\n",
        "\n",
        "# Copy all files from the source path to the destination\n",
        "shutil.copytree(path, output_folder, dirs_exist_ok=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "J035swn5fbn1",
        "outputId": "cf7d6323-8ab8-4525-86f1-2e851c25b009"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.7), please consider upgrading to the latest version (0.3.8).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/scripts'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_script=pd.read_csv('/content/scripts/himym_full_transcripts.csv')"
      ],
      "metadata": {
        "id": "be42tSskfbee"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_script"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "2nnKzgn0fbQX",
        "outputId": "6fbed220-6626-4f03-dcff-a852d46d14f4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  episode      name  \\\n",
              "0      4x02 - The Best Burger in New York    Barney   \n",
              "1      4x02 - The Best Burger in New York       Ted   \n",
              "2      4x02 - The Best Burger in New York    Barney   \n",
              "3      4x02 - The Best Burger in New York      Lily   \n",
              "4      4x02 - The Best Burger in New York       Ted   \n",
              "...                                   ...       ...   \n",
              "24005           2x21 - Something Borrowed      Lily   \n",
              "24006           2x21 - Something Borrowed  Marshall   \n",
              "24007           2x21 - Something Borrowed      Lily   \n",
              "24008           2x21 - Something Borrowed       Ted   \n",
              "24009           2x21 - Something Borrowed      Lily   \n",
              "\n",
              "                                                    line  \n",
              "0       Goliath National Bank. The world leader in cr...  \n",
              "1       Okay, first of all, you look like the last pi...  \n",
              "2       Our company just bought them out in a ruthles...  \n",
              "3       Barney, Marshall didn't quit his last soul-su...  \n",
              "4          So, what do you guys want to do for dinner?\\n  \n",
              "...                                                  ...  \n",
              "24005                Tired. I got married twice today.\\n  \n",
              "24006  So where do you want to do it for the first ti...  \n",
              "24007          What do you think? Bathroom, of course.\\n  \n",
              "24008                                    Please don't.\\n  \n",
              "24009                                        Sorry, Ted.  \n",
              "\n",
              "[24010 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1bfb0bf1-8efa-4b4d-a055-a3a5d93adc84\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>episode</th>\n",
              "      <th>name</th>\n",
              "      <th>line</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4x02 - The Best Burger in New York</td>\n",
              "      <td>Barney</td>\n",
              "      <td>Goliath National Bank. The world leader in cr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4x02 - The Best Burger in New York</td>\n",
              "      <td>Ted</td>\n",
              "      <td>Okay, first of all, you look like the last pi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4x02 - The Best Burger in New York</td>\n",
              "      <td>Barney</td>\n",
              "      <td>Our company just bought them out in a ruthles...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4x02 - The Best Burger in New York</td>\n",
              "      <td>Lily</td>\n",
              "      <td>Barney, Marshall didn't quit his last soul-su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4x02 - The Best Burger in New York</td>\n",
              "      <td>Ted</td>\n",
              "      <td>So, what do you guys want to do for dinner?\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24005</th>\n",
              "      <td>2x21 - Something Borrowed</td>\n",
              "      <td>Lily</td>\n",
              "      <td>Tired. I got married twice today.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24006</th>\n",
              "      <td>2x21 - Something Borrowed</td>\n",
              "      <td>Marshall</td>\n",
              "      <td>So where do you want to do it for the first ti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24007</th>\n",
              "      <td>2x21 - Something Borrowed</td>\n",
              "      <td>Lily</td>\n",
              "      <td>What do you think? Bathroom, of course.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24008</th>\n",
              "      <td>2x21 - Something Borrowed</td>\n",
              "      <td>Ted</td>\n",
              "      <td>Please don't.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24009</th>\n",
              "      <td>2x21 - Something Borrowed</td>\n",
              "      <td>Lily</td>\n",
              "      <td>Sorry, Ted.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24010 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1bfb0bf1-8efa-4b4d-a055-a3a5d93adc84')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1bfb0bf1-8efa-4b4d-a055-a3a5d93adc84 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1bfb0bf1-8efa-4b4d-a055-a3a5d93adc84');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3a55cbfa-96ea-4dea-acbf-8140f0906347\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3a55cbfa-96ea-4dea-acbf-8140f0906347')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3a55cbfa-96ea-4dea-acbf-8140f0906347 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_3235b1e8-49c0-4de7-b0f6-b8b4399b9c2b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_script')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3235b1e8-49c0-4de7-b0f6-b8b4399b9c2b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_script');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_script",
              "summary": "{\n  \"name\": \"df_script\",\n  \"rows\": 24010,\n  \"fields\": [\n    {\n      \"column\": \"episode\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 133,\n        \"samples\": [\n          \"3x07 - Dowisetrepla\",\n          \"6x24 - Challenge Accepted\",\n          \"5x21 - Twin Beds\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Ted\",\n          \"Marshall\",\n          \"Lily\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"line\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 21899,\n        \"samples\": [\n          \"Irregular? Oh, my God. This is it. It's all over.\\n\",\n          \"Dude, you're almost 30. Your mom would be mad at you for eating junk food?\\n\",\n          \"But I love you.\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = df_script\n",
        "\n",
        "# each row  :\n",
        "# if episonde name is the first time : create episod name\n",
        "# person scene : dialogue /n\n",
        "\n",
        "output_file = \"himym_script.txt\"\n",
        "seen_episodes = set()\n",
        "\n",
        "with open(output_folder + '/' + output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    for _, row in df.iterrows():\n",
        "        if row[\"episode\"] not in seen_episodes:\n",
        "            f.write(f\"\\n{row['episode']}\\n\")  # Write episode name\n",
        "            f.write(\"=\" * len(row[\"episode\"]) + \"\\n\")  # Underline episode name\n",
        "            seen_episodes.add(row[\"episode\"])\n",
        "\n",
        "        f.write(f\"{row['name']}: {row['line']}\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "OYTAUvX-kWQ9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Datasets"
      ],
      "metadata": {
        "id": "eOMfpIZXt8Yl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#path =\n",
        "# Find all the files.\n",
        "paths_all = glob.glob(\"scripts/*.txt\")\n",
        "print(sorted(paths_all))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKV9Ox_6uiuc",
        "outputId": "e544cd5b-e490-42a3-8462-1cdd522e8ecf"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['scripts/Friends_Transcript.txt', 'scripts/himym_script.txt', 'scripts/tbbt_script.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paths_all[0].split(\"/\")[1].split(\".\")[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sFqDBQW0umnQ",
        "outputId": "c615339c-0009-4f39-b8ff-16dd83fa00c9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tbbt_script'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Q6Wedfqfvg0H",
        "outputId": "2a3f5faf-ae7e-43c6-a2f5-75b787b6faf9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dataset_/valid'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read files\n",
        "\n",
        "#path =\n",
        "# Find all the files.\n",
        "paths_all = glob.glob(\"scripts/*.txt\")\n",
        "print(sorted(paths_all))\n",
        "\n",
        "\n",
        "# standardize\n",
        "\n",
        "# Standardize.\n",
        "for path in paths_all:\n",
        "\n",
        "  filename=path.split(\"/\")[1].split(\".\")[0]\n",
        "  content = open(path).read()\n",
        "  content = content.lower()\n",
        "  for punctuation in \".,:;?!\":\n",
        "      content = content.replace(punctuation, \" \" + punctuation)\n",
        "  open(path, \"w\").write(content)\n",
        "\n",
        "\n",
        "  #split 80 to 20 for validatoin\n",
        "\n",
        "  content = open(path).read()\n",
        "  split_index = int(len(content) * 0.8) #split index\n",
        "\n",
        "\n",
        "  content_test = content[:split_index] # first 80%\n",
        "  content_valid = content[split_index:] # last 20%\n",
        "\n",
        "\n",
        "\n",
        "  # create two files ,from one file which containts all scripts\n",
        "\n",
        "  dataset_path = \"dataset_\"\n",
        "  dataset_path_all = os.path.join(dataset_path, \"all\")\n",
        "  dataset_path_train = os.path.join(dataset_path, \"train\")\n",
        "  dataset_path_valid = os.path.join(dataset_path, \"valid\")\n",
        "\n",
        "\n",
        "  # create all the folders\n",
        "\n",
        "  for path in [dataset_path, dataset_path_all, dataset_path_train, dataset_path_valid]:\n",
        "      if not os.path.exists(path):\n",
        "          os.mkdir(path)\n",
        "\n",
        "\n",
        "  print(filename)\n",
        "  open(dataset_path_all + \"/{}_all.txt\".format(filename), \"w\").write(content)\n",
        "  open(dataset_path_train + \"/{}_test.txt\".format(filename), \"w\").write(content_test)\n",
        "  open(dataset_path_valid+ \"/{}_valid.txt\".format(filename), \"w\").write(content_valid)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# make folders for train and validation and copy files\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CR5T7G1t_Nn",
        "outputId": "da39585a-696f-4cf4-83d8-8e6b63ca5320"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['scripts/Friends_Transcript.txt', 'scripts/himym_script.txt', 'scripts/tbbt_script.txt']\n",
            "tbbt_script\n",
            "Friends_Transcript\n",
            "himym_script\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size  = 64  # not for SGD! This is a different batch size.\n",
        "seed = 667\n",
        "\n",
        "def create_dataset(dataset_path):\n",
        "    dataset = preprocessing.text_dataset_from_directory(\n",
        "        dataset_path,\n",
        "        labels=None,\n",
        "        batch_size=batch_size,\n",
        "        seed=seed\n",
        "    )\n",
        "    return dataset\n",
        "\n",
        "dataset_original_all = create_dataset(dataset_path_all)\n",
        "dataset_original_train = create_dataset(dataset_path_train)\n",
        "dataset_original_valid = create_dataset(dataset_path_valid)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txYvxFGzvMnb",
        "outputId": "da4a8471-a756-46dc-e1c3-c0bc53373a9d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3 files.\n",
            "Found 3 files.\n",
            "Found 3 files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary_size = 30_000\n",
        "encoder = layers.TextVectorization(\n",
        "    max_tokens=vocabulary_size,\n",
        "    standardize=None,\n",
        "    split=\"whitespace\",\n",
        "    output_mode=\"int\"\n",
        ")\n",
        "encoder.adapt(dataset_original_all)\n",
        "vocabulary = encoder.get_vocabulary()\n",
        "print(vocabulary[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EsPwGZVvskd",
        "outputId": "0460b54f-ae1e-4ab2-9c63-ba0e7b19ccaa"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '[UNK]', '.', ':', ',', 'you', 'i', 'the', '?', 'to', '!', 'a', 'and', 'it', 'that', 'is', 'of', 'in', 'what', 'sheldon', 'oh', 'me', 'this', 'my', 'ross', 'on', 'rachel', 'monica', 'chandler', 'joey', 'no', 'leonard', 'not', 'with', 'just', 'so', 'have', 'know', 'for', 'we', 'do', 'phoebe', 'are', 'was', 'but', 'your', 'penny', 'be', 'yeah', 'okay', 'well', '.)', 'all', 'ted', 'her', 'like', 'at', 'out', 'up', 'right', 'howard', 'about', 'get', 'he', 'hey', 'if', 'can', 'go', 'barney', 'one', 'marshall', \"i'm\", 'raj', 'i’m', 'she', 'here', 'really', 'how', 'there', 'think', 'robin', 'him', 'gonna', \"it's\", 'his', 'lily', 'now', 'want', 'amy', 'look', 'why', 'did', 'going', 'see', 'got', 'good', 'uh', 'it’s', 'as', 'come']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sequence_length = 32\n",
        "vocabulary = encoder.get_vocabulary()\n",
        "padding_token_id = 0\n",
        "\n",
        "\n",
        "def create_dataset_for_autoregression(dataset):\n",
        "  x_inputs = []\n",
        "  y_outputs = []\n",
        "  for stories in dataset:\n",
        "    stories = encoder(stories).numpy() # Does the padding\n",
        "\n",
        "    for story in stories:\n",
        "      story = [index for index in list(story) if index != padding_token_id] # removes padding\n",
        "\n",
        "      # Allowing to generate from sequences that are shorter than sequence length.\n",
        "      padding = [padding_token_id] * sequence_length\n",
        "      story = padding + story\n",
        "\n",
        "      for start_index in range(0,len(story)-sequence_length): # no overflow.\n",
        "          x = story[start_index:start_index + sequence_length]\n",
        "          assert len(x) == sequence_length, \"Should not happen.\"\n",
        "          y = story[start_index + 1 :start_index + sequence_length+1]\n",
        "          assert len(y) == sequence_length , \"should not happen\"\n",
        "\n",
        "          x_inputs += [x]\n",
        "          y_outputs += [y]\n",
        "\n",
        "\n",
        "  # Done,\n",
        "  return tf.data.Dataset.from_tensor_slices((x_inputs, y_outputs))\n",
        "\n",
        "\n",
        "dataset_train = create_dataset_for_autoregression(dataset_original_train)\n",
        "dataset_valid = create_dataset_for_autoregression(dataset_original_valid)"
      ],
      "metadata": {
        "id": "C61L3I0Svuhf"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(indices):\n",
        "  return \" \".join([vocabulary[index] for index in indices if vocabulary[index] != \"\"])\n",
        "\n",
        "for input,output in dataset_train.take(20):\n",
        "  print(decode(input))\n",
        "  print(decode(output))\n",
        "  print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rKSnvPmvyyG",
        "outputId": "d20ae118-c105-45c3-b84f-500d79f2d7db"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "series\n",
            "\n",
            "series\n",
            "series 01\n",
            "\n",
            "series 01\n",
            "series 01 episode\n",
            "\n",
            "series 01 episode\n",
            "series 01 episode 01\n",
            "\n",
            "series 01 episode 01\n",
            "series 01 episode 01 –\n",
            "\n",
            "series 01 episode 01 –\n",
            "series 01 episode 01 – [UNK]\n",
            "\n",
            "series 01 episode 01 – [UNK]\n",
            "series 01 episode 01 – [UNK] [UNK]\n",
            "\n",
            "series 01 episode 01 – [UNK] [UNK]\n",
            "series 01 episode 01 – [UNK] [UNK] scene\n",
            "\n",
            "series 01 episode 01 – [UNK] [UNK] scene\n",
            "series 01 episode 01 – [UNK] [UNK] scene :\n",
            "\n",
            "series 01 episode 01 – [UNK] [UNK] scene :\n",
            "series 01 episode 01 – [UNK] [UNK] scene : a\n",
            "\n",
            "series 01 episode 01 – [UNK] [UNK] scene : a\n",
            "series 01 episode 01 – [UNK] [UNK] scene : a corridor\n",
            "\n",
            "series 01 episode 01 – [UNK] [UNK] scene : a corridor\n",
            "series 01 episode 01 – [UNK] [UNK] scene : a corridor at\n",
            "\n",
            "series 01 episode 01 – [UNK] [UNK] scene : a corridor at\n",
            "series 01 episode 01 – [UNK] [UNK] scene : a corridor at a\n",
            "\n",
            "series 01 episode 01 – [UNK] [UNK] scene : a corridor at a\n",
            "series 01 episode 01 – [UNK] [UNK] scene : a corridor at a sperm\n",
            "\n",
            "series 01 episode 01 – [UNK] [UNK] scene : a corridor at a sperm\n",
            "series 01 episode 01 – [UNK] [UNK] scene : a corridor at a sperm bank\n",
            "\n",
            "series 01 episode 01 – [UNK] [UNK] scene : a corridor at a sperm bank\n",
            "series 01 episode 01 – [UNK] [UNK] scene : a corridor at a sperm bank .\n",
            "\n",
            "series 01 episode 01 – [UNK] [UNK] scene : a corridor at a sperm bank .\n",
            "series 01 episode 01 – [UNK] [UNK] scene : a corridor at a sperm bank . sheldon\n",
            "\n",
            "series 01 episode 01 – [UNK] [UNK] scene : a corridor at a sperm bank . sheldon\n",
            "series 01 episode 01 – [UNK] [UNK] scene : a corridor at a sperm bank . sheldon :\n",
            "\n",
            "series 01 episode 01 – [UNK] [UNK] scene : a corridor at a sperm bank . sheldon :\n",
            "series 01 episode 01 – [UNK] [UNK] scene : a corridor at a sperm bank . sheldon : so\n",
            "\n",
            "series 01 episode 01 – [UNK] [UNK] scene : a corridor at a sperm bank . sheldon : so\n",
            "series 01 episode 01 – [UNK] [UNK] scene : a corridor at a sperm bank . sheldon : so if\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def render_history(history):\n",
        "    plt.title(\"Training loss vs. validation loss\")\n",
        "    plt.plot(history.history[\"loss\"], label=\"loss\")\n",
        "    plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    plt.title(\"Training accuracy vs. validation accuracy\")\n",
        "    plt.plot(history.history[\"accuracy\"], label=\"accuracy\")\n",
        "    plt.plot(history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "6dzbcOoxxEqp"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from re import X\n",
        "def create_transformer( sequence_length = 32 , embedding_size = 64 , layers_number = 6 , num_heads=4):\n",
        "\n",
        "  #functional API.\n",
        "\n",
        "  inputs = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)\n",
        "  embedding=layers.Embedding(vocabulary_size , embedding_size, name='Embedding')(inputs)\n",
        "\n",
        "  positions = tf.range(start=0, limit=sequence_length, delta=1) # [0, 1, 2, ... , 31] constant\n",
        "  positional_embedding = layers.Embedding(sequence_length, embedding_size,name='Positional')(positions)\n",
        "  embedding += positional_embedding\n",
        "\n",
        "  for _ in range( layers_number):\n",
        "\n",
        "    x1 = layers.LayerNormalization(epsilon = 1e-6)(embedding)\n",
        "\n",
        "    attention_output= layers.MultiHeadAttention(\n",
        "\n",
        "                                                num_heads = num_heads,\n",
        "                                                key_dim = embedding_size,\n",
        "                                                dropout = 0.1\n",
        "    )(x1,x1, use_causal_mask = True )  # V/K + Q\n",
        "\n",
        "    # skip connection.\n",
        "    x2 = attention_output + embedding\n",
        "    # Normalize .\n",
        "    x3 = layers.LayerNormalization(epsilon = 1e-6)(x2)\n",
        "\n",
        "    # MLP.\n",
        "\n",
        "    x4  = layers.Dense(embedding_size * 2 , activation = 'gelu')(x3)\n",
        "    x4  = layers.Dense(embedding_size, activation = 'gelu')(x4)\n",
        "\n",
        "\n",
        "    # skip connection\n",
        "\n",
        "    embedding = x4+x2\n",
        "\n",
        "\n",
        "  #Head.\n",
        "  outputs = layers.Dense (vocabulary_size , activation='softmax')(embedding)\n",
        "  return models.Model(inputs , outputs)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model = create_transformer()\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile (\n",
        "\n",
        "               optimizer = 'adam',\n",
        "               loss = 'sparse_categorical_crossentropy',\n",
        "               metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "\n",
        "                    dataset_train.cache().shuffle(20_000).batch(2048),\n",
        "                    epochs= 5 ,\n",
        "                    validation_data = dataset_valid.batch(2048)\n",
        ")\n",
        "\n",
        "render_history(history)\n",
        "\n"
      ],
      "metadata": {
        "id": "RxmopHTUvzWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def generate(model, seed_text, generated_sequence_length, temperature):\n",
        "\n",
        "    seed_text = seed_text.lower()\n",
        "    for punctuation in \".,:;?!\":\n",
        "        seed_text = seed_text.replace(punctuation, \" \" + punctuation)\n",
        "\n",
        "    input_sequence = encoder(seed_text).numpy().tolist()\n",
        "\n",
        "    # Generate the sequence by repeatedly predicting.\n",
        "    while len(input_sequence) < generated_sequence_length:\n",
        "        prediction = model.predict(np.expand_dims(input_sequence, axis=0), verbose=False)\n",
        "        predicted_index = get_index_from_prediction(prediction[0][-1], temperature)\n",
        "        input_sequence.append(predicted_index)\n",
        "\n",
        "    # Convert the generated sequence to a string.\n",
        "    text = decode(input_sequence)\n",
        "    for punctuation in \".,:;?!\":\n",
        "        text = text.replace(\" \" + punctuation, punctuation)\n",
        "    print(text)\n",
        "    print(\"\")\n",
        "\n",
        "\n",
        "\n",
        "def get_index_from_prediction(prediction, temperature=0.0):\n",
        "    \"\"\" Gets an index from a prediction. \"\"\"\n",
        "\n",
        "    # Zero temperature - use the argmax.\n",
        "    if temperature == 0.0:\n",
        "        return np.argmax(prediction)\n",
        "\n",
        "    # Non-zero temperature - do some random magic.\n",
        "    else:\n",
        "        prediction = np.asarray(prediction).astype('float64')\n",
        "        prediction = np.log(prediction) / temperature # softmax formula is : ex/sigma(ex) getting logarithm ,cancels this out\n",
        "        # log amplifies x<1 , of course it negates them\n",
        "        # it T is smaller than 1  , push lower peaks to higher numbers and vise versa\n",
        "\n",
        "        exp_prediction= np.exp(prediction)\n",
        "        prediction = exp_prediction / np.sum(exp_prediction)\n",
        "        probabilities = np.random.multinomial(1, prediction, 1)\n",
        "        return np.argmax(probabilities)\n",
        "\n",
        "\n",
        "def generate_with_padding(model, seed_text, generated_sequence_length, temperature):\n",
        "    seed_text = seed_text.lower()\n",
        "    for punctuation in \".,:;?!\":\n",
        "        seed_text = seed_text.replace(punctuation, \" \" + punctuation)\n",
        "\n",
        "\n",
        "    input_sequence = encoder(seed_text).numpy().tolist()\n",
        "\n",
        "    # Pad the input_sequence if it's shorter than sequence_length\n",
        "    if len(input_sequence) < sequence_length:\n",
        "        input_sequence = [0] * (sequence_length - len(input_sequence)) + input_sequence\n",
        "\n",
        "    # Generate the sequence by repeatedly predicting.\n",
        "    while len(input_sequence) < generated_sequence_length:\n",
        "        sequence = input_sequence[-sequence_length:]\n",
        "        assert len(sequence) == sequence_length\n",
        "\n",
        "        prediction = model.predict(np.expand_dims(sequence, axis=0), verbose=False)\n",
        "        predicted_index = get_index_from_prediction(prediction[0][-1], temperature)\n",
        "\n",
        "        input_sequence.append(predicted_index)\n",
        "\n",
        "    # Convert the generated sequence to a string.\n",
        "    text = decode(input_sequence)\n",
        "    for punctuation in \".,:;?!\":\n",
        "        text = text.replace(\" \" + punctuation, punctuation)\n",
        "    text = text.strip()\n",
        "    print(text)\n",
        "    print(\"\")\n",
        "\n",
        "generate_with_padding(model, \"sheldon chandler and Barney are sitting in a  \", 100, temperature=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fi46vm1zv7Tf",
        "outputId": "d3243507-cc2e-4970-a490-657e07f64aff"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sheldon chandler and barney are sitting in a crib to kiss her bathroom.] ross: all joey is gay opinion! now! [UNK], how you go to remember all of your apartment story? you didnt earn your nanny when you a guy. lewis: that? i am the worse and i would want to believe you. im just just for him. \"so wha then then then [UNK] you\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DAn-ww4p0q7w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}