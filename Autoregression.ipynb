{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPSKeJuYJPKhG8UamDw6Uk7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahabday/NLP_learning/blob/main/Autoregression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Hu3sfOdTBjVY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import preprocessing\n",
        "from tensorflow.keras import models, layers\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Where the text files are going to live.\n",
        "dataset_path = \"dataset\"\n",
        "dataset_path_all = os.path.join(dataset_path, \"all\")\n",
        "dataset_path_train = os.path.join(dataset_path, \"train\")\n",
        "dataset_path_valid = os.path.join(dataset_path, \"valid\")\n",
        "\n",
        "# Just use 20 files.\n",
        "file_number = 20\n",
        "\n",
        "# Gather the corpus if it has not been gathered yet.\n",
        "if not os.path.exists(dataset_path):\n",
        "\n",
        "    # Create all the folders.\n",
        "    for path in [dataset_path, dataset_path_all, dataset_path_train, dataset_path_valid]:\n",
        "        if not os.path.exists(path):\n",
        "            os.mkdir(path)\n",
        "\n",
        "    # Clone the repo.\n",
        "    !git clone https://github.com/vilmibm/lovecraftcorpus\n",
        "\n",
        "    # Find all the files.\n",
        "    paths_all = glob.glob(\"lovecraftcorpus/*.txt\")\n",
        "    print(sorted(paths_all))\n",
        "\n",
        "    # Standardize.\n",
        "    for path in paths_all:\n",
        "        content = open(path).read()\n",
        "        content = content.lower()\n",
        "        for punctuation in \".,:;?!\":\n",
        "            content = content.replace(punctuation, \" \" + punctuation)\n",
        "        open(path, \"w\").write(content)\n",
        "\n",
        "    # Do not use all.\n",
        "    paths_all = paths_all[:file_number]\n",
        "\n",
        "    # Split 80/20.\n",
        "    split_index = int(len(paths_all) * 0.8)\n",
        "    paths_train = paths_all[:split_index]\n",
        "    paths_valid = paths_all[split_index:]\n",
        "\n",
        "    # Copy files.\n",
        "    def copy(paths, destination):\n",
        "        for path in paths:\n",
        "            shutil.copy2(path, destination)\n",
        "    copy(paths_all, dataset_path_all)\n",
        "    copy(paths_train, dataset_path_train)\n",
        "    copy(paths_valid, dataset_path_valid)\n",
        "\n",
        "    # Delete repo.\n",
        "    !rm -rf lovecraftcorpus\n",
        "\n",
        "    # Done.\n",
        "    print(\"Corpus downloaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaN53LpdBuP1",
        "outputId": "b9d28eec-5dfb-42f6-f9de-6937ab9ddde6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'lovecraftcorpus'...\n",
            "remote: Enumerating objects: 74, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 74 (delta 0), reused 3 (delta 0), pack-reused 70 (from 1)\u001b[K\n",
            "Receiving objects: 100% (74/74), 1.12 MiB | 16.38 MiB/s, done.\n",
            "['lovecraftcorpus/alchemist.txt', 'lovecraftcorpus/arthur_jermyn.txt', 'lovecraftcorpus/azathoth.txt', 'lovecraftcorpus/beast.txt', 'lovecraftcorpus/beyond_wall_of_sleep.txt', 'lovecraftcorpus/book.txt', 'lovecraftcorpus/celephais.txt', 'lovecraftcorpus/charles_dexter_ward.txt', 'lovecraftcorpus/clergyman.txt', 'lovecraftcorpus/colour_out_of_space.txt', 'lovecraftcorpus/cool_air.txt', 'lovecraftcorpus/crawling_chaos.txt', 'lovecraftcorpus/cthulhu.txt', 'lovecraftcorpus/dagon.txt', 'lovecraftcorpus/descendent.txt', 'lovecraftcorpus/doorstep.txt', 'lovecraftcorpus/dreams_in_the_witch.txt', 'lovecraftcorpus/dunwich.txt', 'lovecraftcorpus/erich_zann.txt', 'lovecraftcorpus/ex_oblivione.txt', 'lovecraftcorpus/festival.txt', 'lovecraftcorpus/from_beyond.txt', 'lovecraftcorpus/gates_of_silver_key.txt', 'lovecraftcorpus/haunter.txt', 'lovecraftcorpus/he.txt', 'lovecraftcorpus/high_house_mist.txt', 'lovecraftcorpus/hound.txt', 'lovecraftcorpus/hypnos.txt', 'lovecraftcorpus/innsmouth.txt', 'lovecraftcorpus/iranon.txt', 'lovecraftcorpus/juan_romero.txt', 'lovecraftcorpus/kadath.txt', 'lovecraftcorpus/lurking_fear.txt', 'lovecraftcorpus/martins_beach.txt', 'lovecraftcorpus/medusas_coil.txt', 'lovecraftcorpus/memory.txt', 'lovecraftcorpus/moon_bog.txt', 'lovecraftcorpus/mountains_of_madness.txt', 'lovecraftcorpus/nameless.txt', 'lovecraftcorpus/nyarlathotep.txt', 'lovecraftcorpus/old_folk.txt', 'lovecraftcorpus/other_gods.txt', 'lovecraftcorpus/outsider.txt', 'lovecraftcorpus/pharoahs.txt', 'lovecraftcorpus/pickman.txt', 'lovecraftcorpus/picture_house.txt', 'lovecraftcorpus/poetry_of_gods.txt', 'lovecraftcorpus/polaris.txt', 'lovecraftcorpus/randolph_carter.txt', 'lovecraftcorpus/rats_walls.txt', 'lovecraftcorpus/reanimator.txt', 'lovecraftcorpus/redhook.txt', 'lovecraftcorpus/sarnath.txt', 'lovecraftcorpus/shadow_out_of_time.txt', 'lovecraftcorpus/shunned_house.txt', 'lovecraftcorpus/silver_key.txt', 'lovecraftcorpus/street.txt', 'lovecraftcorpus/temple.txt', 'lovecraftcorpus/terrible_old_man.txt', 'lovecraftcorpus/tomb.txt', 'lovecraftcorpus/tree.txt', 'lovecraftcorpus/ulthar.txt', 'lovecraftcorpus/unnamable.txt', 'lovecraftcorpus/vault.txt', 'lovecraftcorpus/what_moon_brings.txt', 'lovecraftcorpus/whisperer.txt', 'lovecraftcorpus/white_ship.txt']\n",
            "Corpus downloaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sLNw0liU8iuT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "czmqXthL8aTY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size  = 32  # not for SGD! This is a different batch size.\n",
        "seed = 667\n",
        "\n",
        "def create_dataset(dataset_path):\n",
        "    dataset = preprocessing.text_dataset_from_directory(\n",
        "        dataset_path,\n",
        "        labels=None,\n",
        "        batch_size=batch_size,\n",
        "        seed=seed\n",
        "    )\n",
        "    return dataset\n",
        "dataset_original_all = create_dataset(dataset_path_all)\n",
        "dataset_original_train = create_dataset(dataset_path_train)\n",
        "dataset_original_valid = create_dataset(dataset_path_valid)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QLn9Hi-UCGcs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cde356a5-a9f0-4052-a688-738c67596f70"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20 files.\n",
            "Found 16 files.\n",
            "Found 4 files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary_size = 10_000\n",
        "encoder = layers.TextVectorization(\n",
        "    max_tokens=vocabulary_size,\n",
        "    standardize=None,\n",
        "    split=\"whitespace\",\n",
        "    output_mode=\"int\"\n",
        ")\n",
        "encoder.adapt(dataset_original_all)\n",
        "vocabulary = encoder.get_vocabulary()\n",
        "print(vocabulary[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9YifWZd8wu0",
        "outputId": "8c2b7899-2270-4dab-b0fa-4099395f85d8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '[UNK]', 'the', ',', 'of', '.', 'and', 'to', 'a', 'in', 'was', 'that', 'had', 'he', 'i', 'it', 'as', 'his', 'with', 'at', 'which', 'on', 'from', 'for', 'we', 'not', 'were', ';', 'but', 'by', 'all', 'be', 'this', 'they', 'my', 'have', 'or', 'could', 'one', 'there', 'him', 'been', 'when', 'an', 'our', 'some', 'no', 'their', 'would', 'old', 'what', 'me', 'about', 'so', 'more', 'is', 'its', 'now', 'seemed', 'out', 'up', 'only', 'did', 'into', 'than', 'those', 'through', 'though', 'them', 'even', 'other', 'after', 'time', 'very', 'who', 'great', 'before', 'any', 'must', 'like', 'things', 'then', 'over', 'if', 'these', 'us', 'came', 'where', 'saw', 'found', 'man', 'whose', 'down', 'certain', 'such', 'yet', 'made', 'might', 'beyond', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sequence_length = 32\n",
        "vocabulary = encoder.get_vocabulary()\n",
        "padding_token_id = 0\n",
        "\n",
        "\n",
        "def create_dataset_for_autoregression(dataset):\n",
        "  x_inputs = []\n",
        "  y_outputs = []\n",
        "  for stories in dataset:\n",
        "    stories = encoder(stories).numpy() # Does the padding\n",
        "\n",
        "    for story in stories:\n",
        "      story = [index for index in list(story) if index != padding_token_id] # removes padding\n",
        "\n",
        "      # Allowing to generate from sequences that are shorter than sequence length.\n",
        "      padding = [padding_token_id] * sequence_length\n",
        "      story = padding + story\n",
        "\n",
        "      for start_index in range(0,len(story)-sequence_length): # no overflow.\n",
        "          x = story[start_index:start_index + sequence_length]\n",
        "          assert len(x) == sequence_length, \"Should not happen.\"\n",
        "          y = story[start_index + 1 :start_index + sequence_length+1]\n",
        "          assert len(y) == sequence_length , \"should not happen\"\n",
        "\n",
        "          x_inputs += [x]\n",
        "          y_outputs += [y]\n",
        "\n",
        "\n",
        "  # Done,\n",
        "  return tf.data.Dataset.from_tensor_slices((x_inputs, y_outputs))\n",
        "\n",
        "\n",
        "dataset_train = create_dataset_for_autoregression(dataset_original_train)\n",
        "dataset_valid = create_dataset_for_autoregression(dataset_original_valid)"
      ],
      "metadata": {
        "id": "FpPokyGL8t_r"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(indices):\n",
        "  return \" \".join([vocabulary[index] for index in indices if vocabulary[index] != \"\"])\n",
        "\n",
        "for input,output in dataset_train.take(20):\n",
        "  print(decode(input))\n",
        "  print(decode(output))\n",
        "  print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8QaNeuL70-j",
        "outputId": "426127fb-c406-4a88-950a-bb6dfb8fa2e6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "the\n",
            "\n",
            "the\n",
            "the terrible\n",
            "\n",
            "the terrible\n",
            "the terrible old\n",
            "\n",
            "the terrible old\n",
            "the terrible old man\n",
            "\n",
            "the terrible old man\n",
            "the terrible old man the\n",
            "\n",
            "the terrible old man the\n",
            "the terrible old man the inhabitants\n",
            "\n",
            "the terrible old man the inhabitants\n",
            "the terrible old man the inhabitants of\n",
            "\n",
            "the terrible old man the inhabitants of\n",
            "the terrible old man the inhabitants of kingsport\n",
            "\n",
            "the terrible old man the inhabitants of kingsport\n",
            "the terrible old man the inhabitants of kingsport say\n",
            "\n",
            "the terrible old man the inhabitants of kingsport say\n",
            "the terrible old man the inhabitants of kingsport say and\n",
            "\n",
            "the terrible old man the inhabitants of kingsport say and\n",
            "the terrible old man the inhabitants of kingsport say and think\n",
            "\n",
            "the terrible old man the inhabitants of kingsport say and think\n",
            "the terrible old man the inhabitants of kingsport say and think many\n",
            "\n",
            "the terrible old man the inhabitants of kingsport say and think many\n",
            "the terrible old man the inhabitants of kingsport say and think many things\n",
            "\n",
            "the terrible old man the inhabitants of kingsport say and think many things\n",
            "the terrible old man the inhabitants of kingsport say and think many things about\n",
            "\n",
            "the terrible old man the inhabitants of kingsport say and think many things about\n",
            "the terrible old man the inhabitants of kingsport say and think many things about the\n",
            "\n",
            "the terrible old man the inhabitants of kingsport say and think many things about the\n",
            "the terrible old man the inhabitants of kingsport say and think many things about the terrible\n",
            "\n",
            "the terrible old man the inhabitants of kingsport say and think many things about the terrible\n",
            "the terrible old man the inhabitants of kingsport say and think many things about the terrible old\n",
            "\n",
            "the terrible old man the inhabitants of kingsport say and think many things about the terrible old\n",
            "the terrible old man the inhabitants of kingsport say and think many things about the terrible old man\n",
            "\n",
            "the terrible old man the inhabitants of kingsport say and think many things about the terrible old man\n",
            "the terrible old man the inhabitants of kingsport say and think many things about the terrible old man which\n",
            "\n",
            "the terrible old man the inhabitants of kingsport say and think many things about the terrible old man which\n",
            "the terrible old man the inhabitants of kingsport say and think many things about the terrible old man which generally\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def render_history(history):\n",
        "    plt.title(\"Training loss vs. validation loss\")\n",
        "    plt.plot(history.history[\"loss\"], label=\"loss\")\n",
        "    plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    plt.title(\"Training accuracy vs. validation accuracy\")\n",
        "    plt.plot(history.history[\"accuracy\"], label=\"accuracy\")\n",
        "    plt.plot(history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "aF86Ta92YmGy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "Ej8L9ZnhY7Ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 16\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Embedding(vocabulary_size, embedding_size))\n",
        "model.add(layers.LSTM(embedding_size, return_sequences=True) )\n",
        "model.add(layers.Dense(vocabulary_size,activation=\"softmax\"))\n",
        "\n",
        "\n",
        "model.build(input_shape = (None, sequence_length))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile (\n",
        "\n",
        "               optimizer = 'adam',\n",
        "               loss = 'sparse_categorical_crossentropy',\n",
        "               metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# history = model.fit(\n",
        "\n",
        "#                     dataset_train.cache().shuffle(10_000).batch(1024),\n",
        "#                     epochs= 10 ,\n",
        "#                     validation_data = dataset_valid.batch(1024)\n",
        "# )\n",
        "\n",
        "render_history(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "-S3saQ4_AZKa",
        "outputId": "c9c27a3b-d2b4-4959-d130-e65f703d2091"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m)              │         \u001b[38;5;34m160,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m)              │           \u001b[38;5;34m2,112\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10000\u001b[0m)           │         \u001b[38;5;34m170,000\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">160,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">170,000</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m332,112\u001b[0m (1.27 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">332,112</span> (1.27 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m332,112\u001b[0m (1.27 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">332,112</span> (1.27 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'history' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-cfada5958bab>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mrender_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def generate(model, seed_text, generated_sequence_length, temperature):\n",
        "\n",
        "    seed_text = seed_text.lower()\n",
        "    for punctuation in \".,:;?!\":\n",
        "        seed_text = seed_text.replace(punctuation, \" \" + punctuation)\n",
        "\n",
        "    input_sequence = encoder(seed_text).numpy().tolist()\n",
        "\n",
        "    # Generate the sequence by repeatedly predicting.\n",
        "    while len(input_sequence) < generated_sequence_length:\n",
        "        prediction = model.predict(np.expand_dims(input_sequence, axis=0), verbose=False)\n",
        "        predicted_index = get_index_from_prediction(prediction[0][-1], temperature)\n",
        "        input_sequence.append(predicted_index)\n",
        "\n",
        "    # Convert the generated sequence to a string.\n",
        "    text = decode(input_sequence)\n",
        "    for punctuation in \".,:;?!\":\n",
        "        text = text.replace(\" \" + punctuation, punctuation)\n",
        "    print(text)\n",
        "    print(\"\")\n",
        "\n",
        "\n",
        "def get_index_from_prediction(prediction, temperature=0.0):\n",
        "    \"\"\" Gets an index from a prediction. \"\"\"\n",
        "\n",
        "    # Zero temperature - use the argmax.\n",
        "    if temperature == 0.0:\n",
        "        return np.argmax(prediction)\n",
        "\n",
        "    # Non-zero temperature - do some random magic.\n",
        "    else:\n",
        "        prediction = np.asarray(prediction).astype('float64')\n",
        "        prediction = np.log(prediction) / temperature # softmax formula is : ex/sigma(ex) getting logarithm ,cancels this out\n",
        "        # log amplifies x<1 , of course it negates them\n",
        "        # it T is smaller than 1  , push lower peaks to higher numbers and vise versa\n",
        "\n",
        "        exp_prediction= np.exp(prediction)\n",
        "        prediction = exp_prediction / np.sum(exp_prediction)\n",
        "        probabilities = np.random.multinomial(1, prediction, 1)\n",
        "        return np.argmax(probabilities)\n",
        "\n",
        "\n",
        "generate(model, \"we are all doomed\", 100, temperature=1.0)"
      ],
      "metadata": {
        "id": "YqVWMVEwaaiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "61bjnjwb_MWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Transformes"
      ],
      "metadata": {
        "id": "JfZjiWv4_PrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from re import X\n",
        "def create_transformer( sequence_length = 32 , enbedding_size = 16 , layers_number = 4 , num_heads=4):\n",
        "\n",
        "  #functional API.\n",
        "\n",
        "  inputs = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)\n",
        "  embedding=layers.Embedding(vocabulary_size , embedding_size, name='Embedding')(inputs)\n",
        "\n",
        "  positions = tf.range(start=0, limit=sequence_length, delta=1) # [0, 1, 2, ... , 31] constant\n",
        "  positional_embedding = layers.Embedding(sequence_length, embedding_size,name='Positional')(positions)\n",
        "  embedding += positional_embedding\n",
        "\n",
        "  for _ in range( layers_number):\n",
        "\n",
        "    x1 = layers.LayerNormalization(epsilon = 1e-6)(embedding)\n",
        "\n",
        "    attention_output= layers.MultiHeadAttention(\n",
        "\n",
        "                                                num_heads = num_heads,\n",
        "                                                key_dim = embedding_size,\n",
        "                                                dropout = 0.1\n",
        "    )(x1,x1, use_causal_mask = True )  # V/K + Q\n",
        "\n",
        "    # skip connection.\n",
        "    x2 = attention_output + embedding\n",
        "    # Normalize .\n",
        "    x3 = layers.LayerNormalization(epsilon = 1e-6)(x2)\n",
        "\n",
        "    # MLP.\n",
        "\n",
        "    x4  = layers.Dense(embedding_size * 2 , activation = 'gelu')(x3)\n",
        "    x4  = layers.Dense(embedding_size, activation = 'gelu')(x4)\n",
        "\n",
        "\n",
        "    # skip connection\n",
        "\n",
        "    embedidng = x4+x2\n",
        "\n",
        "\n",
        "\n",
        "    return models.Model(inputs , x2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model = create_transformer()\n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dZL7fWGS_PJv",
        "outputId": "d1626fb8-131d-48b0-a269-0bc216449fea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_8             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │        \u001b[38;5;34m160,000\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ Embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │             \u001b[38;5;34m32\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │          \u001b[38;5;34m4,304\u001b[0m │ layer_normalization_1… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_6 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n",
              "│                           │                        │                │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_8             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">160,000</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,304</span> │ layer_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n",
              "│                           │                        │                │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m164,336\u001b[0m (641.94 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">164,336</span> (641.94 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m164,336\u001b[0m (641.94 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">164,336</span> (641.94 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "trr87976_g0_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}