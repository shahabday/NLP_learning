{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMF6RJx60PMgF7X5tbZ+PW0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahabday/NLP_learning/blob/main/Autoregression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Hu3sfOdTBjVY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import preprocessing\n",
        "from tensorflow.keras import models, layers\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Where the text files are going to live.\n",
        "dataset_path = \"dataset\"\n",
        "dataset_path_all = os.path.join(dataset_path, \"all\")\n",
        "dataset_path_train = os.path.join(dataset_path, \"train\")\n",
        "dataset_path_valid = os.path.join(dataset_path, \"valid\")\n",
        "\n",
        "# Just use 20 files.\n",
        "file_number = 20\n",
        "\n",
        "# Gather the corpus if it has not been gathered yet.\n",
        "if not os.path.exists(dataset_path):\n",
        "\n",
        "    # Create all the folders.\n",
        "    for path in [dataset_path, dataset_path_all, dataset_path_train, dataset_path_valid]:\n",
        "        if not os.path.exists(path):\n",
        "            os.mkdir(path)\n",
        "\n",
        "    # Clone the repo.\n",
        "    !git clone https://github.com/vilmibm/lovecraftcorpus\n",
        "\n",
        "    # Find all the files.\n",
        "    paths_all = glob.glob(\"lovecraftcorpus/*.txt\")\n",
        "    print(sorted(paths_all))\n",
        "\n",
        "    # Standardize.\n",
        "    for path in paths_all:\n",
        "        content = open(path).read()\n",
        "        content = content.lower()\n",
        "        for punctuation in \".,:;?!\":\n",
        "            content = content.replace(punctuation, \" \" + punctuation)\n",
        "        open(path, \"w\").write(content)\n",
        "\n",
        "    # Do not use all.\n",
        "    paths_all = paths_all[:file_number]\n",
        "\n",
        "    # Split 80/20.\n",
        "    split_index = int(len(paths_all) * 0.8)\n",
        "    paths_train = paths_all[:split_index]\n",
        "    paths_valid = paths_all[split_index:]\n",
        "\n",
        "    # Copy files.\n",
        "    def copy(paths, destination):\n",
        "        for path in paths:\n",
        "            shutil.copy2(path, destination)\n",
        "    copy(paths_all, dataset_path_all)\n",
        "    copy(paths_train, dataset_path_train)\n",
        "    copy(paths_valid, dataset_path_valid)\n",
        "\n",
        "    # Delete repo.\n",
        "    !rm -rf lovecraftcorpus\n",
        "\n",
        "    # Done.\n",
        "    print(\"Corpus downloaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaN53LpdBuP1",
        "outputId": "f6e2b0e8-ffb7-45ac-cc0e-de6376b3afc3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'lovecraftcorpus'...\n",
            "remote: Enumerating objects: 74, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 74 (delta 0), reused 3 (delta 0), pack-reused 70 (from 1)\u001b[K\n",
            "Receiving objects: 100% (74/74), 1.12 MiB | 2.89 MiB/s, done.\n",
            "['lovecraftcorpus/alchemist.txt', 'lovecraftcorpus/arthur_jermyn.txt', 'lovecraftcorpus/azathoth.txt', 'lovecraftcorpus/beast.txt', 'lovecraftcorpus/beyond_wall_of_sleep.txt', 'lovecraftcorpus/book.txt', 'lovecraftcorpus/celephais.txt', 'lovecraftcorpus/charles_dexter_ward.txt', 'lovecraftcorpus/clergyman.txt', 'lovecraftcorpus/colour_out_of_space.txt', 'lovecraftcorpus/cool_air.txt', 'lovecraftcorpus/crawling_chaos.txt', 'lovecraftcorpus/cthulhu.txt', 'lovecraftcorpus/dagon.txt', 'lovecraftcorpus/descendent.txt', 'lovecraftcorpus/doorstep.txt', 'lovecraftcorpus/dreams_in_the_witch.txt', 'lovecraftcorpus/dunwich.txt', 'lovecraftcorpus/erich_zann.txt', 'lovecraftcorpus/ex_oblivione.txt', 'lovecraftcorpus/festival.txt', 'lovecraftcorpus/from_beyond.txt', 'lovecraftcorpus/gates_of_silver_key.txt', 'lovecraftcorpus/haunter.txt', 'lovecraftcorpus/he.txt', 'lovecraftcorpus/high_house_mist.txt', 'lovecraftcorpus/hound.txt', 'lovecraftcorpus/hypnos.txt', 'lovecraftcorpus/innsmouth.txt', 'lovecraftcorpus/iranon.txt', 'lovecraftcorpus/juan_romero.txt', 'lovecraftcorpus/kadath.txt', 'lovecraftcorpus/lurking_fear.txt', 'lovecraftcorpus/martins_beach.txt', 'lovecraftcorpus/medusas_coil.txt', 'lovecraftcorpus/memory.txt', 'lovecraftcorpus/moon_bog.txt', 'lovecraftcorpus/mountains_of_madness.txt', 'lovecraftcorpus/nameless.txt', 'lovecraftcorpus/nyarlathotep.txt', 'lovecraftcorpus/old_folk.txt', 'lovecraftcorpus/other_gods.txt', 'lovecraftcorpus/outsider.txt', 'lovecraftcorpus/pharoahs.txt', 'lovecraftcorpus/pickman.txt', 'lovecraftcorpus/picture_house.txt', 'lovecraftcorpus/poetry_of_gods.txt', 'lovecraftcorpus/polaris.txt', 'lovecraftcorpus/randolph_carter.txt', 'lovecraftcorpus/rats_walls.txt', 'lovecraftcorpus/reanimator.txt', 'lovecraftcorpus/redhook.txt', 'lovecraftcorpus/sarnath.txt', 'lovecraftcorpus/shadow_out_of_time.txt', 'lovecraftcorpus/shunned_house.txt', 'lovecraftcorpus/silver_key.txt', 'lovecraftcorpus/street.txt', 'lovecraftcorpus/temple.txt', 'lovecraftcorpus/terrible_old_man.txt', 'lovecraftcorpus/tomb.txt', 'lovecraftcorpus/tree.txt', 'lovecraftcorpus/ulthar.txt', 'lovecraftcorpus/unnamable.txt', 'lovecraftcorpus/vault.txt', 'lovecraftcorpus/what_moon_brings.txt', 'lovecraftcorpus/whisperer.txt', 'lovecraftcorpus/white_ship.txt']\n",
            "Corpus downloaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sLNw0liU8iuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "czmqXthL8aTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size  = 32  # not for SGD! This is a different batch size.\n",
        "seed = 667\n",
        "\n",
        "def create_dataset(dataset_path):\n",
        "    dataset = preprocessing.text_dataset_from_directory(\n",
        "        dataset_path,\n",
        "        labels=None,\n",
        "        batch_size=batch_size,\n",
        "        seed=seed\n",
        "    )\n",
        "    return dataset\n",
        "dataset_original_all = create_dataset(dataset_path_all)\n",
        "dataset_original_train = create_dataset(dataset_path_train)\n",
        "dataset_original_valid = create_dataset(dataset_path_valid)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QLn9Hi-UCGcs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb9cdcc3-0143-43f1-ccfc-8cf2a23c2e7a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20 files.\n",
            "Found 16 files.\n",
            "Found 4 files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary_size = 10_000\n",
        "encoder = layers.TextVectorization(\n",
        "    max_tokens=vocabulary_size,\n",
        "    standardize=None,\n",
        "    split=\"whitespace\",\n",
        "    output_mode=\"int\"\n",
        ")\n",
        "encoder.adapt(dataset_original_all)\n",
        "vocabulary = encoder.get_vocabulary()\n",
        "print(vocabulary[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9YifWZd8wu0",
        "outputId": "b0db291d-36c3-424f-b866-eb57c97017d6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '[UNK]', 'the', ',', 'of', '.', 'and', 'to', 'a', 'in', 'was', 'that', 'had', 'he', 'i', 'it', 'as', 'his', 'with', 'at', 'which', 'on', 'from', 'for', 'we', 'not', 'were', ';', 'but', 'by', 'all', 'be', 'this', 'they', 'my', 'have', 'or', 'could', 'one', 'there', 'him', 'been', 'when', 'an', 'our', 'some', 'no', 'their', 'would', 'old', 'what', 'me', 'about', 'so', 'more', 'is', 'its', 'now', 'seemed', 'out', 'up', 'only', 'did', 'into', 'than', 'those', 'through', 'though', 'them', 'even', 'other', 'after', 'time', 'very', 'who', 'great', 'before', 'any', 'must', 'like', 'things', 'then', 'over', 'if', 'these', 'us', 'came', 'where', 'saw', 'found', 'man', 'whose', 'down', 'certain', 'such', 'yet', 'made', 'might', 'beyond', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sequence_length = 32\n",
        "vocabulary = encoder.get_vocabulary()\n",
        "padding_token_id = 0\n",
        "\n",
        "\n",
        "def create_dataset_for_autoregression(dataset):\n",
        "  x_inputs = []\n",
        "  y_outputs = []\n",
        "  for stories in dataset:\n",
        "    stories = encoder(stories).numpy() # Does the padding\n",
        "\n",
        "    for story in stories:\n",
        "      story = [index for index in list(story) if index != padding_token_id] # removes padding\n",
        "\n",
        "      # Allowing to generate from sequences that are shorter than sequence length.\n",
        "      padding = [padding_token_id] * sequence_length\n",
        "      story = padding + story\n",
        "\n",
        "      for start_index in range(0,len(story)-sequence_length): # no overflow.\n",
        "          x = story[start_index:start_index + sequence_length]\n",
        "          assert len(x) == sequence_length, \"Should not happen.\"\n",
        "          y = story[start_index + 1 :start_index + sequence_length+1]\n",
        "          assert len(y) == sequence_length , \"should not happen\"\n",
        "\n",
        "          x_inputs += [x]\n",
        "          y_outputs += [y]\n",
        "\n",
        "\n",
        "  # Done,\n",
        "  return tf.data.Dataset.from_tensor_slices((x_inputs, y_outputs))\n",
        "\n",
        "\n",
        "dataset_train = create_dataset_for_autoregression(dataset_original_train)\n",
        "dataset_valid = create_dataset_for_autoregression(dataset_original_valid)"
      ],
      "metadata": {
        "id": "FpPokyGL8t_r"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(indices):\n",
        "  return \" \".join([vocabulary[index] for index in indices if vocabulary[index] != \"\"])\n",
        "\n",
        "for input,output in dataset_train.take(20):\n",
        "  print(decode(input))\n",
        "  print(decode(output))\n",
        "  print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8QaNeuL70-j",
        "outputId": "411e784e-6d07-4411-e168-7080b0eaceb9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "the\n",
            "\n",
            "the\n",
            "the terrible\n",
            "\n",
            "the terrible\n",
            "the terrible old\n",
            "\n",
            "the terrible old\n",
            "the terrible old man\n",
            "\n",
            "the terrible old man\n",
            "the terrible old man the\n",
            "\n",
            "the terrible old man the\n",
            "the terrible old man the inhabitants\n",
            "\n",
            "the terrible old man the inhabitants\n",
            "the terrible old man the inhabitants of\n",
            "\n",
            "the terrible old man the inhabitants of\n",
            "the terrible old man the inhabitants of kingsport\n",
            "\n",
            "the terrible old man the inhabitants of kingsport\n",
            "the terrible old man the inhabitants of kingsport say\n",
            "\n",
            "the terrible old man the inhabitants of kingsport say\n",
            "the terrible old man the inhabitants of kingsport say and\n",
            "\n",
            "the terrible old man the inhabitants of kingsport say and\n",
            "the terrible old man the inhabitants of kingsport say and think\n",
            "\n",
            "the terrible old man the inhabitants of kingsport say and think\n",
            "the terrible old man the inhabitants of kingsport say and think many\n",
            "\n",
            "the terrible old man the inhabitants of kingsport say and think many\n",
            "the terrible old man the inhabitants of kingsport say and think many things\n",
            "\n",
            "the terrible old man the inhabitants of kingsport say and think many things\n",
            "the terrible old man the inhabitants of kingsport say and think many things about\n",
            "\n",
            "the terrible old man the inhabitants of kingsport say and think many things about\n",
            "the terrible old man the inhabitants of kingsport say and think many things about the\n",
            "\n",
            "the terrible old man the inhabitants of kingsport say and think many things about the\n",
            "the terrible old man the inhabitants of kingsport say and think many things about the terrible\n",
            "\n",
            "the terrible old man the inhabitants of kingsport say and think many things about the terrible\n",
            "the terrible old man the inhabitants of kingsport say and think many things about the terrible old\n",
            "\n",
            "the terrible old man the inhabitants of kingsport say and think many things about the terrible old\n",
            "the terrible old man the inhabitants of kingsport say and think many things about the terrible old man\n",
            "\n",
            "the terrible old man the inhabitants of kingsport say and think many things about the terrible old man\n",
            "the terrible old man the inhabitants of kingsport say and think many things about the terrible old man which\n",
            "\n",
            "the terrible old man the inhabitants of kingsport say and think many things about the terrible old man which\n",
            "the terrible old man the inhabitants of kingsport say and think many things about the terrible old man which generally\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def render_history(history):\n",
        "    plt.title(\"Training loss vs. validation loss\")\n",
        "    plt.plot(history.history[\"loss\"], label=\"loss\")\n",
        "    plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    plt.title(\"Training accuracy vs. validation accuracy\")\n",
        "    plt.plot(history.history[\"accuracy\"], label=\"accuracy\")\n",
        "    plt.plot(history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "aF86Ta92YmGy"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "Ej8L9ZnhY7Ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 16\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Embedding(vocabulary_size, embedding_size))\n",
        "model.add(layers.LSTM(embedding_size, return_sequences=True) )\n",
        "model.add(layers.Dense(vocabulary_size,activation=\"softmax\"))\n",
        "\n",
        "\n",
        "model.build(input_shape = (None, sequence_length))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile (\n",
        "\n",
        "               optimizer = 'adam',\n",
        "               loss = 'sparse_categorical_crossentropy',\n",
        "               metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "\n",
        "                    dataset_train.cache().shuffle(10_000).batch(1024),\n",
        "                    epochs= 10 ,\n",
        "                    validation_data = dataset_valid.batch(1024)\n",
        ")\n",
        "\n",
        "render_history(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "-S3saQ4_AZKa",
        "outputId": "417ff5ce-fc87-41c6-eaf1-3f1659407d07"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_10 (\u001b[38;5;33mEmbedding\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m)              │         \u001b[38;5;34m160,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m)              │           \u001b[38;5;34m2,112\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10000\u001b[0m)           │         \u001b[38;5;34m170,000\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">160,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">170,000</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m332,112\u001b[0m (1.27 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">332,112</span> (1.27 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m332,112\u001b[0m (1.27 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">332,112</span> (1.27 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-47051c57b2fc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                     \u001b[0mdataset_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    917\u001b[0m           )\n\u001b[1;32m    918\u001b[0m       )\n\u001b[0;32m--> 919\u001b[0;31m       return self._concrete_variable_creation_fn._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    920\u001b[0m           \u001b[0mfiltered_flat_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_variable_creation_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def generate(model, seed_text, generated_sequence_length, temperature):\n",
        "\n",
        "    seed_text = seed_text.lower()\n",
        "    for punctuation in \".,:;?!\":\n",
        "        seed_text = seed_text.replace(punctuation, \" \" + punctuation)\n",
        "\n",
        "    input_sequence = encoder(seed_text).numpy().tolist()\n",
        "\n",
        "    # Generate the sequence by repeatedly predicting.\n",
        "    while len(input_sequence) < generated_sequence_length:\n",
        "        prediction = model.predict(np.expand_dims(input_sequence, axis=0), verbose=False)\n",
        "        predicted_index = get_index_from_prediction(prediction[0][-1], temperature)\n",
        "        input_sequence.append(predicted_index)\n",
        "\n",
        "    # Convert the generated sequence to a string.\n",
        "    text = decode(input_sequence)\n",
        "    for punctuation in \".,:;?!\":\n",
        "        text = text.replace(\" \" + punctuation, punctuation)\n",
        "    print(text)\n",
        "    print(\"\")\n",
        "\n",
        "\n",
        "def get_index_from_prediction(prediction, temperature=0.0):\n",
        "    \"\"\" Gets an index from a prediction. \"\"\"\n",
        "\n",
        "    # Zero temperature - use the argmax.\n",
        "    if temperature == 0.0:\n",
        "        return np.argmax(prediction)\n",
        "\n",
        "    # Non-zero temperature - do some random magic.\n",
        "    else:\n",
        "        prediction = np.asarray(prediction).astype('float64')\n",
        "        prediction = np.log(prediction) / temperature # softmax formula is : ex/sigma(ex) getting logarithm ,cancels this out\n",
        "        # log amplifies x<1 , of course it negates them\n",
        "        # it T is smaller than 1  , push lower peaks to higher numbers and vise versa\n",
        "\n",
        "        exp_prediction= np.exp(prediction)\n",
        "        prediction = exp_prediction / np.sum(exp_prediction)\n",
        "        probabilities = np.random.multinomial(1, prediction, 1)\n",
        "        return np.argmax(probabilities)\n",
        "\n",
        "\n",
        "generate(model, \"we are all doomed\", 100, temperature=1.0)"
      ],
      "metadata": {
        "id": "YqVWMVEwaaiq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}